{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import skimage as skimage\n",
    "from skimage import transform, color, exposure\n",
    "from skimage.transform import rotate\n",
    "from skimage.viewer import ImageViewer\n",
    "import sys\n",
    "sys.path.append(\"game/\")\n",
    "import wrapped_flappy_bird as game\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import json\n",
    "from keras.initializers import normal, identity\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD , Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "GAME = 'bird' # the name of the game being played for log files\n",
    "CONFIG = 'nothreshold'\n",
    "ACTIONS = 2 # number of valid actions\n",
    "GAMMA = 0.99 # decay rate of past observations\n",
    "OBSERVATION = 3200. # timesteps to observe before training\n",
    "EXPLORE = 3000000. # frames over which to anneal epsilon\n",
    "FINAL_EPSILON = 0.0001 # final value of epsilon\n",
    "INITIAL_EPSILON = 0.1 # starting value of epsilon\n",
    "REPLAY_MEMORY = 50000 # number of previous transitions to remember\n",
    "BATCH = 32 # size of minibatch\n",
    "FRAME_PER_ACTION = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "img_rows , img_cols = 80, 80\n",
    "#Convert image into Black and white\n",
    "img_channels = 4 #We stack 4 frames\n",
    "\n",
    "def buildmodel():\n",
    "    print(\"Now we build the model\")\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 8, 8, subsample=(4, 4), border_mode='same',input_shape=(img_rows,img_cols,img_channels)))  #80*80*4\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 4, 4, subsample=(2, 2), border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "   \n",
    "    adam = Adam(lr=LEARNING_RATE)\n",
    "    model.compile(loss='mse',optimizer=adam)\n",
    "    print(\"We finish building the model\")\n",
    "    return model\n",
    "\n",
    "def trainNetwork(model,args):\n",
    "    # open up a game state to communicate with emulator\n",
    "    game_state = game.GameState()\n",
    "\n",
    "    # store the previous observations in replay memory\n",
    "    D = deque()\n",
    "\n",
    "    # get the first state by doing nothing and preprocess the image to 80x80x4\n",
    "    do_nothing = np.zeros(ACTIONS)\n",
    "    do_nothing[0] = 1\n",
    "    x_t, r_0, terminal = game_state.frame_step(do_nothing) # x_t contains the image\n",
    "    \n",
    "    x_t = skimage.color.rgb2gray(x_t)\n",
    "    x_t = skimage.transform.resize(x_t,(80,80))\n",
    "    x_t = skimage.exposure.rescale_intensity(x_t,out_range=(0,255))\n",
    "\n",
    "    x_t = x_t / 255.0\n",
    "\n",
    "    s_t = np.stack((x_t, x_t, x_t, x_t), axis=2)\n",
    "    #print (s_t.shape)\n",
    "\n",
    "    #In Keras, need to reshape\n",
    "    s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])  #1*80*80*4\n",
    "\n",
    "    \n",
    "\n",
    "    if args['mode'] == 'Run':\n",
    "        OBSERVE = 999999999    #We keep observe, never train\n",
    "        epsilon = FINAL_EPSILON\n",
    "        print (\"Now we load weight\")\n",
    "        model.load_weights(\"model.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        model.compile(loss='mse',optimizer=adam)\n",
    "        print (\"Weight load successfully\")    \n",
    "    else:                       #We go to training mode\n",
    "        OBSERVE = OBSERVATION #3200\n",
    "        epsilon = INITIAL_EPSILON #0.1\n",
    "\n",
    "    t = 0\n",
    "    while (True):\n",
    "        loss = 0\n",
    "        Q_sa = 0\n",
    "        action_index = 0\n",
    "        r_t = 0\n",
    "        a_t = np.zeros([ACTIONS])\n",
    "        #choose an action epsilon greedy\n",
    "        if t % FRAME_PER_ACTION == 0:\n",
    "            if random.random() <= epsilon:\n",
    "                print(\"----------Random Action----------\")\n",
    "                action_index = random.randrange(ACTIONS)\n",
    "                a_t[action_index] = 1\n",
    "            else:\n",
    "                q = model.predict(s_t)       #input a stack of 4 images, get the prediction\n",
    "                max_Q = np.argmax(q)\n",
    "                action_index = max_Q\n",
    "                a_t[max_Q] = 1\n",
    "\n",
    "        #We reduced the epsilon gradually\n",
    "        if epsilon > FINAL_EPSILON and t > OBSERVE:\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE\n",
    "\n",
    "        #run the selected action and observed next state and reward\n",
    "        x_t1_colored, r_t, terminal = game_state.frame_step(a_t)\n",
    "\n",
    "        x_t1 = skimage.color.rgb2gray(x_t1_colored)\n",
    "        x_t1 = skimage.transform.resize(x_t1,(80,80))\n",
    "        x_t1 = skimage.exposure.rescale_intensity(x_t1, out_range=(0, 255))\n",
    "\n",
    "\n",
    "        x_t1 = x_t1 / 255.0\n",
    "\n",
    "\n",
    "        x_t1 = x_t1.reshape(1, x_t1.shape[0], x_t1.shape[1], 1) #1x80x80x1\n",
    "        print(s_t[:, :, :, :3].shape)\n",
    "        s_t1 = np.append(x_t1, s_t[:, :, :, :3], axis=3)\n",
    "\n",
    "        # store the transition in D\n",
    "        D.append((s_t, action_index, r_t, s_t1, terminal))\n",
    "        if len(D) > REPLAY_MEMORY: # We only want to keep the 50000 memories\n",
    "            D.popleft()\n",
    "\n",
    "        #only train if done observing\n",
    "        if t > OBSERVE:\n",
    "            #sample a minibatch to train on\n",
    "            minibatch = random.sample(D, BATCH)\n",
    "\n",
    "            #Now we do the experience replay\n",
    "            state_t, action_t, reward_t, state_t1, terminal = zip(*minibatch)\n",
    "            state_t = np.concatenate(state_t)\n",
    "            state_t1 = np.concatenate(state_t1)\n",
    "            targets = model.predict(state_t)\n",
    "            Q_sa = model.predict(state_t1)\n",
    "            targets[range(BATCH), action_t] = reward_t + GAMMA*np.max(Q_sa, axis=1)*np.invert(terminal)\n",
    "\n",
    "            loss += model.train_on_batch(state_t, targets)\n",
    "\n",
    "        s_t = s_t1\n",
    "        t = t + 1\n",
    "\n",
    "        # save progress every 10000 iterations\n",
    "        if t % 1000 == 0:\n",
    "            print(\"Now we save model\")\n",
    "            model.save_weights(\"model.h5\", overwrite=True)\n",
    "            with open(\"model.json\", \"w\") as outfile:\n",
    "                json.dump(model.to_json(), outfile)\n",
    "\n",
    "        # print info\n",
    "        state = \"\"\n",
    "        if t <= OBSERVE:\n",
    "            state = \"observe\"\n",
    "        elif t > OBSERVE and t <= OBSERVE + EXPLORE:\n",
    "            state = \"explore\"\n",
    "        else:\n",
    "            state = \"train\"\n",
    "\n",
    "        print(\"TIMESTEP\", t, \"/ STATE\", state, \\\n",
    "            \"/ EPSILON\", epsilon, \"/ ACTION\", action_index, \"/ REWARD\", r_t, \\\n",
    "            \"/ Q_MAX \" , np.max(Q_sa), \"/ Loss \", loss)\n",
    "\n",
    "    print(\"Episode finished!\")\n",
    "    print(\"************************\")\n",
    "\n",
    "def playGame(args):\n",
    "    model = buildmodel()\n",
    "    trainNetwork(model,args)\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Description of your program')\n",
    "    parser.add_argument('-m','--mode', help='Train / Run', required=True)\n",
    "    args = vars(parser.parse_args())\n",
    "    playGame(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('N', 'J'), ('i', 'i'), ('n', 'n'), ('t', 't')}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zip merges the relative values together into one single record\n",
    "name = ['Nitin', 'Jitin']\n",
    "address=['Texas','Tamil Nadu']\n",
    "mapped = zip(*name)\n",
    "set(mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-69e65ddea5ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflappybird\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlappyBird\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ple'"
     ]
    }
   ],
   "source": [
    "from ple.games.flappybird import FlappyBird"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
